#+TITLE Deap Learning From Scratch
* 第1章　Python入门
** 1.1 Python是什么
** 1.2 Python的安装
*** 1.2.1　Python版本
*** 1.2.2　使用的外部库
NumPy 是用于数值计算的库,提供了很多高级的数学算法和便利的数组(矩阵)操作方法。
Matplotlib 是用来画图的库。使用 Matplotlib 能将实验结果可视化,并在视觉上确认深度学习运行期间的数据。
*** 1.2.3　Anaconda发行版
** 1.3 Python解释器
*** 1.3.1　算术计算
*** 1.3.2　数据类型
type()
*** 1.3.3　变量
*** 1.3.4　列表
*** 1.3.5　字典
*** 1.3.6　布尔型
*** 1.3.7　if 语句
*** 1.3.8　for 语句
*** 1.3.9　函数
** 1.4 Python脚本文件
*** 1.4.1　保存为文件
*** 1.4.2　类　
** 1.5 NumPy　
*** 1.5.1　导入NumPy
import numpy as np
*** 1.5.2　生成NumPy数组　
numpy.ndarray
[[file:example/1-5-2.py]]
*** 1.5.3　NumPy 的算术运算　
[[file:example/1-5-3.py]]
"对应元素的”的英文是 element-wise
在 NumPy 数组的各个元素和标量之间进行运算。这个功能也被称为广播(详见后文)。
*** 1.5.4　NumPy的N维数组
矩阵形状可以通过 shape 查看.
矩阵元素的数据类型可以通过 dtype 查看.
数学上将一维数组称为向量,将二维数组称为矩阵。
可以将一般化之后的向量或矩阵等统称为张量 (tensor)。
[[file:example/1-5-4.py]]
*** 1.5.5　广播　
标量被扩展成了矩阵的形状,然后再与矩阵进行乘法运算。这个巧妙的功能称为广播 (broadcast)。
[[file:example/1-5-5.py]]
*** 1.5.6　访问元素　
[[file:example/1-5-6.py]]
** 1.6 Matplotlib　
*** ^
图形的绘制和数据的可视化
*** 1.6.1　绘制简单图形　
matplotlib 的 pyplot 模块绘制图形
[[file:example/1-6-1.py]]
*** 1.6.2　pyplot 的功能　
[[file:example/1-6-2.py]]
*** 1.6.3　显示图像
[[file:example/1-6-3.py]]
** 1.7 小结　
* 第2章　感知机　
** 2.1 感知机是什么　
** 2.2 简单逻辑电路　
*** 2.2.1　与门　
*** 2.2.2　与非门和或门　
** 2.3 感知机的实现　
*** 2.3.1　简单的实现　
*** 2.3.2　导入权重和偏置　
*** 2.3.3　使用权重和偏置的实现　
** 2.4 感知机的局限性　
*** 2.4.1　异或门　
*** 2.4.2　线性和非线性　
** 2.5 多层感知机　
*** 2.5.1　已有门电路的组合　
*** 2.5.2　异或门的实现　
** 2.6 从与非门到计算机　
** 2.7 小结　
* 第3章　神经网络　
** 3.1 从感知机到神经网络　
*** 3.1.1　神经网络的例子　
*** 3.1.2　复习感知机　
*** 3.1.3　激活函数登场　
** 3.2 激活函数　
*** 3.2.1　sigmoid 函数　
*** 3.2.2　阶跃函数的实现　
*** 3.2.3　阶跃函数的图形　
*** 3.2.4　sigmoid 函数的实现　
*** 3.2.5　sigmoid 函数和阶跃函数的比较　
*** 3.2.6　非线性函数　
*** 3.2.7　ReLU函数　
** 3.3 多维数组的运算　
*** 3.3.1　多维数组　
*** 3.3.2　矩阵乘法　
*** 3.3.3　神经网络的内积　
** 3.4　3 层神经网络的实现　
*** 3.4.1　符号确认　
*** 3.4.2　各层间信号传递的实现　
*** 3.4.3　代码实现小结　
** 3.5 输出层的设计　
*** 3.5.1　恒等函数和softmax 函数　
*** 3.5.2　实现softmax 函数时的注意事项　
*** 3.5.3　softmax 函数的特征　
*** 3.5.4　输出层的神经元数量　
** 3.6 手写数字识别　
*** 3.6.1　MNIST数据集　
*** 3.6.2　神经网络的推理处理　
*** 3.6.3　批处理　
** 3.7 小结　
* 第4章　神经网络的学习　
** 4.1 从数据中学习　
*** 4.1.1　数据驱动　
*** 4.1.2　训练数据和测试数据　
** 4.2 损失函数　
*** 4.2.1　均方误差　
*** 4.2.2　交叉熵误差　
*** 4.2.3　mini-batch 学习　
*** 4.2.4　mini-batch 版交叉熵误差的实现　
*** 4.2.5　为何要设定损失函数　
** 4.3 数值微分　
*** 4.3.1　导数　
*** 4.3.2　数值微分的例子　
*** 4.3.3　偏导数　
** 4.4 梯度
*** 4.4.1　梯度法
*** 4.4.2　神经网络的梯度
** 4.5 学习算法的实现
*** 4.5.1　2 层神经网络的类
*** 4.5.2　mini-batch 的实现
*** 4.5.3　基于测试数据的评价
** 4.6 小结
* 第5章　误差反向传播法
** 5.1 计算图
*** 5.1.1　用计算图求解
*** 5.1.2　局部计算
*** 5.1.3　为何用计算图解题
** 5.2 链式法则
*** 5.2.1　计算图的反向传播
*** 5.2.2　什么是链式法则
*** 5.2.3　链式法则和计算图
** 5.3 反向传播
*** 5.3.1　加法节点的反向传播
*** 5.3.2　乘法节点的反向传播
*** 5.3.3　苹果的例子
** 5.4 简单层的实现
*** 5.4.1　乘法层的实现
*** 5.4.2　加法层的实现
** 5.5 激活函数层的实现
*** 5.5.1　ReLU层
*** 5.5.2　Sigmoid 层
** 5.6 AffineSoftmax层的实现
*** 5.6.1　Affine层
*** 5.6.2　批版本的Affine层
*** 5.6.3　Softmax-with-Loss 层
** 5.7 误差反向传播法的实现
*** 5.7.1　神经网络学习的全貌图
*** 5.7.2　对应误差反向传播法的神经网络的实现
*** 5.7.3　误差反向传播法的梯度确认
*** 5.7.4　使用误差反向传播法的学习
** 5.8 小结
* 第6章　与学习相关的技巧
** 6.1 参数的更新
*** 6.1.1　探险家的故事
*** 6.1.2　SGD
*** 6.1.3　SGD的缺点
*** 6.1.4　Momentum
*** 6.1.5　AdaGrad
*** 6.1.6　Adam
*** 6.1.7　使用哪种更新方法呢
*** 6.1.8　基于MNIST数据集的更新方法的比较
** 6.2 权重的初始值
*** 6.2.1　可以将权重初始值设为0 吗
*** 6.2.2　隐藏层的激活值的分布
*** 6.2.3　ReLU的权重初始值
*** 6.2.4　基于MNIST数据集的权重初始值的比较
** 6.3 Batch Normalization
*** 6.3.1　Batch Normalization 的算法
*** 6.3.2　Batch Normalization 的评估
** 6.4 正则化
*** 6.4.1　过拟合
*** 6.4.2　权值衰减
*** 6.4.3　Dropout
** 6.5 超参数的验证
*** 6.5.1　验证数据
*** 6.5.2　超参数的最优化
*** 6.5.3　超参数最优化的实现
** 6.6 小结
* 第7章　卷积神经网络
** 7.1 整体结构
** 7.2 卷积层
*** 7.2.1　全连接层存在的问题
*** 7.2.2　卷积运算
*** 7.2.3　填充
*** 7.2.4　步幅
*** 7.2.5　3 维数据的卷积运算
*** 7.2.6　结合方块思考
*** 7.2.7　批处理
** 7.3 池化层
** 7.4 卷积层和池化层的实现
*** 7.4.1　4 维数组
*** 7.4.2　基于im2col 的展开
*** 7.4.3　卷积层的实现
*** 7.4.4　池化层的实现
** 7.5 CNN的实现
** 7.6 CNN的可视化
*** 7.6.1　第1 层权重的可视化
*** 7.6.2　基于分层结构的信息提取
** 7.7 具有代表性的CNN
*** 7.7.1　LeNet
*** 7.7.2　AlexNet
** 7.8 小结
* 第8章　深度学习
** 8.1 加深网络
*** 8.1.1　向更深的网络出发
*** 8.1.2　进一步提高识别精度
*** 8.1.3　加深层的动机
** 8.2 深度学习的小历史
*** 8.2.1　ImageNet
*** 8.2.2　VGG
*** 8.2.3　GoogLeNet
*** 8.2.4　ResNet
** 8.3 深度学习的高速化
*** 8.3.1　需要努力解决的问题
*** 8.3.2　基于GPU的高速化
*** 8.3.3　分布式学习
*** 8.3.4　运算精度的位数缩减
** 8.4 深度学习的应用案例
*** 8.4.1　物体检测
*** 8.4.2　图像分割
*** 8.4.3　图像标题的生成
** 8.5 深度学习的未来
*** 8.5.1　图像风格变换
*** 8.5.2　图像的生成
*** 8.5.3　自动驾驶
*** 8.5.4　Deep Q-Network（强化学习）
** 8.6 小结
* 附录A　Softmax-with-Loss 层的计算图
** A.1 正向传播
** A.2 反向传播
** A.3 小结
